{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.data.path.append(\"../local_packages/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "tenders = pd.read_csv(\"../data/uk_tenders_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenders.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we extract anything helpful from tender title?\n",
    "\n",
    "tenders[\"title_lower\"] = tenders['tender_title'].str.lower()\n",
    "\n",
    "def remove_punct(ptext):\n",
    "    # replace any punctuation with nothing \"\", effectively removing it\n",
    "    ptext = re.sub(string=ptext,\n",
    "                   pattern=\"[{}]\".format(string.punctuation), \n",
    "                   repl=\"\")\n",
    "    return ptext\n",
    "\n",
    "# TODO this doesn't parse out all our \"[]\" chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty titles\n",
    "tenders[\"title_lower\"].replace('', np.nan, inplace=True)\n",
    "tenders.dropna(subset=['title_lower'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply removing punctuation function to all elements in the column \"abstract\"\n",
    "tenders['title_processed'] = tenders['title_lower'].apply(remove_punct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tenders['title_tokens'] = tenders['title_processed'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to remove stopwords from list of tokens\n",
    "def clean_stopwords(tokens):\n",
    "    # define stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # add bespoke for this\n",
    "    stop_words.add(\"amp\")\n",
    "    stop_words.add(\"test\")\n",
    "    # loop through each token and if the word isn't in the set \n",
    "    # of stopwords keep it\n",
    "    return [item for item in tokens if item not in stop_words]\n",
    "tenders['tokens_no_stops'] = tenders['title_tokens'].apply(clean_stopwords)\n",
    "tenders.tokens_no_stops.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(ptoken):\n",
    "    # create stemming object\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in ptoken]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenders[\"title_stemmed\"] = tenders[\"tokens_no_stops\"].apply(stemming)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lemmatise() function\n",
    "\n",
    "def lemmatise(ptokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in ptokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenders[\"title_lemmatised\"] = tenders[\"tokens_no_stops\"].apply(lemmatise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenders.title_lemmatised.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenders.tokens_no_stops = tenders.tokens_no_stops.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenders.title_lemmatised = tenders.title_lemmatised.astype(\"string\")\n",
    "tenders.title_stemmed = tenders.title_stemmed.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = Counter()\n",
    "tenders[\"title_lemmatised\"].str.split(\"'\").apply(results.update)\n",
    "#tenders.title_stemmed.str.split(\"'\").apply(results.update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokens:\", sum(dict(results).values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out the tokens and counts into lists\n",
    "tokens, counts = zip(*results.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotall(px, py):\n",
    "    \n",
    "    plt.xticks(fontsize=12, rotation=90)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel(\"Tokens\")\n",
    "    plt.bar(px, py)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotall(tokens[3:30], counts[3:30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the token data as string\n",
    "#tenders['tokens_lem'] = tenders['tokens_no_stops'].apply(return_tostring)\n",
    "text = \" \".join(tenders['title_lemmatised'])\n",
    "text = text.replace(\"'\", \"\")\n",
    " \n",
    "\n",
    "# The text string is then passed to the wordcloud function:\n",
    "wordcloud = WordCloud(max_font_size=50, \n",
    "                      max_words=100, \n",
    "                      background_color=\"white\").generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig(\"uk_tender_titles_world.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edm-water",
   "language": "python",
   "name": "edm-water"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
